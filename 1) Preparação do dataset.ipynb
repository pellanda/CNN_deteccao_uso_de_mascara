{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook que separa o dataset em arquivos de treino e teste (validação) para serem usados pelo próximo notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coloque os arquivos Jupyter e a pasta com as imagens no mesmo diretório, caso altere o nome dos arquivos, atualizar o caminho no código abaixo.\n",
    "\n",
    "O dataset foi baixado do github (https://github.com/prajnasb/observations/tree/master/experiements/data) contendo 1.376 imagens sendo 690 de pessoas com máscara e 686 de pessoas sem máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de pessoas com máscara: 690\n",
      "Número de imagens de pessoas sem máscara:: 686\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de imagens de pessoas com máscara:\",len(os.listdir('imagens/com_mascara')))\n",
    "print(\"Número de imagens de pessoas sem máscara::\",len(os.listdir('imagens/sem_mascara')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens: 1376\n",
      "Percentual de pessoas com mascara: 50.145348837209305%, número de imagens: 690\n",
      "Percentual de pessoas sem mascara: 49.854651162790695%, número de imagens: 686\n"
     ]
    }
   ],
   "source": [
    "def data_summary(caminho_das_imagens):\n",
    "    \n",
    "    com_mascara = caminho_das_imagens+'com_mascara'\n",
    "    sem_mascara = caminho_das_imagens+'sem_mascara'\n",
    "        \n",
    "    # número de arquivos (imagens) que estão na pasta nomeada 'com_mascara' que representam pessoas usando mascara\n",
    "    m_pos = len(os.listdir(com_mascara))\n",
    "    # número de arquivos (imagens) que estão na pasta nomeada 'sem_mascara' que representam pessoas sem mascara\n",
    "    m_neg = len(os.listdir(sem_mascara))\n",
    "    # number de todas imagens\n",
    "    m = (m_pos+m_neg)\n",
    "    \n",
    "    pos_prec = (m_pos* 100.0)/ m\n",
    "    neg_prec = (m_neg* 100.0)/ m\n",
    "    \n",
    "    print(f\"Número de imagens: {m}\")\n",
    "    print(f\"Percentual de pessoas com mascara: {pos_prec}%, número de imagens: {m_pos}\")\n",
    "    print(f\"Percentual de pessoas sem mascara: {neg_prec}%, número de imagens: {m_neg}\")\n",
    "    \n",
    "caminho_das_imagens = 'imagens/'    \n",
    "data_summary(caminho_das_imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para separar o dataset\n",
    "\n",
    "Crie uma pasta chamada data e dentro delas duas pastas, train e validation com as pastas yes e no dentro de cada uma delas para que a função abaixo possa separar e salvar as imagens nas pastas criadas.\n",
    "\n",
    "Vamos fazer a separação das imagens deixando 80% das imagens para treino e 20% delas para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    dataset = []\n",
    "    \n",
    "    for unitData in os.listdir(SOURCE):\n",
    "        data = SOURCE + unitData\n",
    "        if(os.path.getsize(data) > 0):\n",
    "            dataset.append(unitData)\n",
    "        else:\n",
    "            print('Skipped ' + unitData)\n",
    "            print('Invalid file i.e zero size')\n",
    "    \n",
    "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
    "    test_set_length = int(len(dataset) - train_set_length)\n",
    "    shuffled_set = random.sample(dataset, len(dataset))\n",
    "    train_set = dataset[0:train_set_length]\n",
    "    test_set = dataset[-test_set_length:]\n",
    "       \n",
    "    for unitData in train_set:\n",
    "        temp_train_set = SOURCE + unitData\n",
    "        final_train_set = TRAINING + unitData\n",
    "        copyfile(temp_train_set, final_train_set)\n",
    "    \n",
    "    for unitData in test_set:\n",
    "        temp_test_set = SOURCE + unitData\n",
    "        final_test_set = TESTING + unitData\n",
    "        copyfile(temp_test_set, final_test_set)\n",
    "        \n",
    "        \n",
    "YES_SOURCE_DIR = \"imagens/com_mascara/\"\n",
    "TRAINING_YES_DIR = \"data/train/yes/\"\n",
    "TESTING_YES_DIR = \"data/validation/yes/\"\n",
    "NO_SOURCE_DIR = \"imagens/sem_mascara/\"\n",
    "TRAINING_NO_DIR = \"data/train/no/\"\n",
    "TESTING_NO_DIR = \"data/validation/no/\"\n",
    "split_size = .8\n",
    "split_data(YES_SOURCE_DIR, TRAINING_YES_DIR, TESTING_YES_DIR, split_size)\n",
    "split_data(NO_SOURCE_DIR, TRAINING_NO_DIR, TESTING_NO_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de pessoas com máscara para treino: 552\n",
      "Número de imagens de pessoas com máscara para validação: 138\n",
      "Número de imagens de pessoas sem máscara para treino: 548\n",
      "Número de imagens de pessoas sem máscara para validação: 138\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de imagens de pessoas com máscara para treino:\", len(os.listdir('data/train/yes/')))\n",
    "print(\"Número de imagens de pessoas com máscara para validação:\", len(os.listdir('data/validation/yes/')))\n",
    "print(\"Número de imagens de pessoas sem máscara para treino:\", len(os.listdir('data/train/no/')))\n",
    "print(\"Número de imagens de pessoas sem máscara para validação:\", len(os.listdir('data/validation/no/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalizamos a parte de separação e preparação do dataset. Agora podemos ir para o notebook com o modelo para iniciarmos a segunda etapa do projeto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
